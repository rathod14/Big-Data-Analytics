{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "from pyspark.ml import feature\n",
    "from pyspark.ml import regression\n",
    "from pyspark.sql import functions as fn\n",
    "from pyspark.sql import Row\n",
    "from pyspark import sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning: Use exclusively Spark. Do not use Pandas at all in this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Dataframes and Spark ML\n",
    "\n",
    "In this section, you will learn to create dataframes from messy data and then perform simple regression on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some mysterious process generating data, stored in `/datasets/host_server_requests`, with the following format:\n",
    "\n",
    "`feature1|feature2|...|featurem => outcome`\n",
    "\n",
    "`feature1` can be either \"HOST\" or \"SERVER\" and from feature $2$ through $m$ are floating point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_rdd = sc.textFile('/datasets/host_server_requests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "\n",
    "In this question, you will create a function `process_line` that receives a line from `/datasets/host_server_requests` and returns a `Row` object with the following columns: \n",
    "\n",
    "- You will codify the first feature as a column `f1` with a `1` if the source is `HOST` and `0` otherwise\n",
    "- You will create 7 other features that you assign to columns `f2`, `f3`, ..., through `f8`\n",
    "- Finally, you will assign the outcome to the column `label`\n",
    "- Remember to make all features of type `float`.\n",
    "\n",
    "For the following code:\n",
    "\n",
    "\n",
    "```python\n",
    "requests_rdd.map(process_line).take(10)\n",
    "```\n",
    "\n",
    "it should generate the following:\n",
    "\n",
    "```python\n",
    "[Row(f1=1.0, f2=2e-05, f3=0.80279, f4=-0.09174, f5=0.04041, f6=-0.22504, f7=-0.0504, f8=0.58149, label=163.877101489),\n",
    " Row(f1=1.0, f2=5e-05, f3=-0.00454, f4=-0.0211, f5=0.00174, f6=-0.11684, f7=0.19182, f8=-0.23745, label=-105.023368852),\n",
    " Row(f1=1.0, f2=0.00015, f3=-0.10437, f4=0.04869, f5=0.18333, f6=-0.21864, f7=0.27638, f8=-0.13441, label=-115.011801582),\n",
    " Row(f1=1.0, f2=-0.00015, f3=0.27118, f4=0.14526, f5=0.06101, f6=0.13401, f7=0.06237, f8=-0.74065, label=-122.623452696),\n",
    " Row(f1=1.0, f2=-6e-05, f3=0.1413, f4=0.12084, f5=0.05452, f6=0.09272, f7=0.2534, f8=-0.65331, label=-117.130523174),\n",
    " Row(f1=1.0, f2=-8e-05, f3=-0.41534, f4=-0.04205, f5=-0.00724, f6=-0.07463, f7=0.13273, f8=0.19112, label=-73.5775668047),\n",
    " Row(f1=1.0, f2=-8e-05, f3=-0.45937, f4=-0.23509, f5=-0.05679, f6=0.06077, f7=-0.49597, f8=-0.30668, label=-137.37933148),\n",
    " Row(f1=0.0, f2=2e-05, f3=-0.23465, f4=0.07345, f5=-0.07217, f6=-0.19256, f7=-0.14377, f8=-0.15183, label=-162.804738349),\n",
    " Row(f1=0.0, f2=-7e-05, f3=-0.10321, f4=0.27467, f5=0.04058, f6=-0.24541, f7=0.08631, f8=-0.2979, label=-212.111291232),\n",
    " Row(f1=1.0, f2=-7e-05, f3=-0.01039, f4=-0.00453, f5=-0.01352, f6=-0.05199, f7=-0.3772, f8=-0.19641, label=-91.5022329392)]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ae027852de73d98e3776430bff639156",
     "grade": false,
     "grade_id": "cell-244fd5f7c0138b60",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def process_line(value):\n",
    "    a=value.replace(' =>  ','|')\n",
    "    b=a.split('|')\n",
    "    c = str(b[0])\n",
    "    if c=='HOST':\n",
    "        n=1.0\n",
    "    else:\n",
    "        n=0.0\n",
    "\n",
    "    row_label =Row(\n",
    "    f1= n,\n",
    "    f2=float(b[1]),\n",
    "    f3=float(b[2]),\n",
    "    f4=float(b[3]),\n",
    "    f5=float(b[4]),\n",
    "    f6=float(b[5]),\n",
    "    f7=float(b[6]),\n",
    "    f8=float(b[7]),\n",
    "    label=float(b[8]))\n",
    "    return row_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(f1=0.0, f2=8e-05, f3=0.45592, f4=0.25362, f5=-0.12878, f6=-0.0693, f7=-0.1474, f8=-0.53736, label=-106.947151761),\n",
       " Row(f1=0.0, f2=-1e-05, f3=0.10405, f4=-0.17047, f5=0.10127, f6=0.13776, f7=0.66619, f8=0.32221, label=127.061566761),\n",
       " Row(f1=1.0, f2=-1e-05, f3=-0.72394, f4=0.31161, f5=0.06975, f6=0.0086, f7=-0.44817, f8=-0.22976, label=-170.222653879),\n",
       " Row(f1=1.0, f2=0.00024, f3=-0.12887, f4=-0.01287, f5=0.18377, f6=-0.07004, f7=0.10632, f8=-0.40884, label=-127.850350049),\n",
       " Row(f1=1.0, f2=6e-05, f3=-0.06767, f4=0.08402, f5=0.14438, f6=-0.19704, f7=0.2839, f8=-0.12487, label=-110.295233798),\n",
       " Row(f1=1.0, f2=5e-05, f3=0.59406, f4=0.25195, f5=-0.00541, f6=-0.05218, f7=0.12202, f8=-0.1285, label=27.7039261796),\n",
       " Row(f1=0.0, f2=-8e-05, f3=-0.08562, f4=-0.00398, f5=-0.17124, f6=-0.13839, f7=-0.23696, f8=-0.814, label=-301.722572842),\n",
       " Row(f1=1.0, f2=-0.0001, f3=-0.28606, f4=-0.00447, f5=-0.10446, f6=-0.25006, f7=-0.03288, f8=-0.87445, label=-361.98704195),\n",
       " Row(f1=0.0, f2=-0.00018, f3=0.02462, f4=0.03503, f5=0.04794, f6=0.00395, f7=0.22638, f8=-0.39012, label=-158.114779137),\n",
       " Row(f1=1.0, f2=0.0001, f3=0.57047, f4=0.09443, f5=-0.0398, f6=-0.19704, f7=-0.36438, f8=-0.13402, label=-21.0376612977)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it here\n",
    "requests_rdd.map(process_line).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2fe0fd15181720aed141c4ccf80f4bbd",
     "grade": true,
     "grade_id": "cell-b4947d69e22e2f22",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(len(requests_rdd.map(process_line).first()), 9)\n",
    "np.testing.assert_equal(requests_rdd.map(process_line).count(), 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "\n",
    "Transform the `requests_rdd` RDD into a Spark 2.0 DataFrame and store it in `requests_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "887c47376104f469159443a9dbe2c2d9",
     "grade": false,
     "grade_id": "cell-b3baf345ff984885",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "requests_df=spark.createDataFrame(requests_rdd.map(process_line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1d0ecca803966f38a4c48122772e830e",
     "grade": true,
     "grade_id": "cell-333768d7c8281274",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(type(requests_df), sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(set(requests_df.columns), {'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'label'})\n",
    "np.testing.assert_equal(requests_df.count(), 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "\n",
    "In this question, we will explore the data. We have a hypothesis that depending on whether the request was from the \"HOST\" or \"SERVER\" (`f1` column), there are significant difference in the outcome (`label` column).\n",
    "\n",
    "You will find whether this is true by computing two quantities for each group of `f1`. You will compute the mean outcome and the *standard error of the mean* or SE of the outcome. The equation for SE of a variable $x$ is:\n",
    "\n",
    "$$\\text{SE}(x) = \\frac{\\text{std}(x)}{\\sqrt{n}}$$\n",
    "\n",
    "From `requests_df`, create a dataframe `summary_df` that contains, for each value of `f1`, the mean `label` as a column `mlabel` and the SEM of `label` as a column `semlabel`. For the SE equation, use the *sample standard devivation* computed by `fn.stddev_samp`. **Hint: perform an aggregate operation and use appropriate combinations of functions in the package `fn`. Rename columns appropriately**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f95851055354ab8dc2ec05ccf7c57ec9",
     "grade": false,
     "grade_id": "cell-15727d5a477764c8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "x=requests_df.groupBy('f1').agg(fn.avg('label').alias('mlabel'))\n",
    "y=requests_df.groupBy('f1').agg((fn.stddev('label')/(fn.sqrt(fn.count('f1')))).alias('semlabel'))\n",
    "summary_df=x.join(y,on='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema of `summary_df` should look like:\n",
    "\n",
    "```python\n",
    "summary_df.printSchema()\n",
    "```\n",
    "```console\n",
    "root\n",
    " |-- f1: double (nullable = true)\n",
    " |-- mlabel: double (nullable = true)\n",
    " |-- semlabel: double (nullable = true)\n",
    "\n",
    "```\n",
    "The mean label for each `f1` feature should be:\n",
    "\n",
    "```python\n",
    "summary_df.select('f1', 'mlabel').show()\n",
    "```\n",
    "\n",
    "```console\n",
    "+---+------------------+\n",
    "| f1|            mlabel|\n",
    "+---+------------------+\n",
    "|0.0|-29.61175341232892|\n",
    "|1.0|-12.62243193686321|\n",
    "+---+------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "01274b653620c538a46bccfa72ef3b1c",
     "grade": true,
     "grade_id": "cell-0f48704616a8f55c",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts\n",
    "np.testing.assert_equal(summary_df.count(), 2)\n",
    "np.testing.assert_equal(set(summary_df.columns), {'f1', 'mlabel', 'semlabel'})\n",
    "np.testing.assert_approx_equal(summary_df.rdd.map(lambda r: r.mlabel).sum(), -42.23418534919213,\n",
    "                              significant=3)\n",
    "np.testing.assert_approx_equal(summary_df.rdd.map(lambda r: r.semlabel).sum(), 3.503568410619124,\n",
    "                              significant=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistically, we say that a mean $\\overline{x}$ is *statistically* different from another mean $\\overline{y}$ if it is not within 2 standard errors of the mean of x (i.e., $\\overline{y} \\not\\in \\{\\overline{x} \\pm 2\\text{SE}(x)\\}$). Discuss whether you think the mean label for f1 = 0 is statistically different from the mean label for f1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+------------------+\n",
      "| f1|             mlabel|          semlabel|\n",
      "+---+-------------------+------------------+\n",
      "|0.0|-29.611753412328927|1.7554606758419875|\n",
      "|1.0| -12.62243193686321|1.7481077347771363|\n",
      "+---+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display it to make your argument\n",
    "summary_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 pts for your answer below:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "47b519124f162219100057c7b90984ba",
     "grade": true,
     "grade_id": "cell-55c3ae319a99bc6c",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Yes the mean label for f1 = 0.0 is statistically different from the mean label for f1 = 1.1 because 2 standard deviation of f1 = 0.0 is approx -26.101. But the mean of f1 = 1.0 is -12.622 which is approximately  about 9.680 standard deviation away from the mean of f1 = 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4:\n",
    "\n",
    "Use the transformer `VectorAssembler` to create a dataframe that puts all columns `f1`, `f2`, ..., `f8` from `requests_df` into a column named `features`. Assign the vector assembler object into a variable `va` and the new dataframe into the variable  `features_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9b8e718f4d06bf724fb9be5673a5ad75",
     "grade": false,
     "grade_id": "cell-56d045d1b2c78b89",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "va = VectorAssembler(inputCols=['f1','f2','f3','f4','f5','f6','f7','f8'], \n",
    "                            outputCol='features')\n",
    "features_df=va.transform(requests_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema of the new dataframe should be like this:\n",
    "\n",
    "```python\n",
    "features_df.printSchema()\n",
    "```\n",
    "\n",
    "```console\n",
    "root\n",
    " |-- f1: double (nullable = true)\n",
    " |-- f2: double (nullable = true)\n",
    " |-- f3: double (nullable = true)\n",
    " |-- f4: double (nullable = true)\n",
    " |-- f5: double (nullable = true)\n",
    " |-- f6: double (nullable = true)\n",
    " |-- f7: double (nullable = true)\n",
    " |-- f8: double (nullable = true)\n",
    " |-- label: double (nullable = true)\n",
    " |-- features: vector (nullable = true)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+--------+--------+-------+--------+--------+--------------+--------------------+\n",
      "| f1|     f2|      f3|      f4|      f5|     f6|      f7|      f8|         label|            features|\n",
      "+---+-------+--------+--------+--------+-------+--------+--------+--------------+--------------------+\n",
      "|0.0| 8.0E-5| 0.45592| 0.25362|-0.12878|-0.0693| -0.1474|-0.53736|-106.947151761|[0.0,8.0E-5,0.455...|\n",
      "|0.0|-1.0E-5| 0.10405|-0.17047| 0.10127|0.13776| 0.66619| 0.32221| 127.061566761|[0.0,-1.0E-5,0.10...|\n",
      "|1.0|-1.0E-5|-0.72394| 0.31161| 0.06975| 0.0086|-0.44817|-0.22976|-170.222653879|[1.0,-1.0E-5,-0.7...|\n",
      "+---+-------+--------+--------+--------+-------+--------+--------+--------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try it here\n",
    "features_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7f41db05c38db0e4e7325099be89cd82",
     "grade": true,
     "grade_id": "cell-505b09bb3262a7ad",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(type(features_df), sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(set(features_df.columns), \n",
    "                        {'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'features', 'label'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5:\n",
    "\n",
    "Run a linear regression model on `features_df` using the `features` column to predict the `label` column. Store the transformer fit to the data in the `lr_model` variable (the transformer is what the estimator's `fit` function returns). Use the transformer to create a dataframe named `predictions_df` with two columns: `label` and `prediction` based on the `features_df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bf7c8c1d895958b567e5aae92cf6a2e0",
     "grade": false,
     "grade_id": "cell-73fa24e4562cc788",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+\n",
      "|         label|         prediction|\n",
      "+--------------+-------------------+\n",
      "|-106.947151761| -98.40908603208513|\n",
      "| 127.061566761| 107.50923895501401|\n",
      "|-170.222653879|-165.34222232721729|\n",
      "|-127.850350049|-107.50493927151456|\n",
      "|-110.295233798|-109.90475992921165|\n",
      "+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import regression\n",
    "from pyspark.ml import feature\n",
    "lr_estimator = regression.LinearRegression(featuresCol=\"features\", \n",
    "                     labelCol='label')\n",
    "lr_model=lr_estimator.fit(features_df)\n",
    "prediction_df=lr_model.transform(features_df)\n",
    "predictions_df=prediction_df.select(['label','prediction'])\n",
    "predictions_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataframe should be in `predictions_df`. Running `predictions_df.show(5)` should produce something like\n",
    "\n",
    "```python\n",
    "predictions_df.show(5)\n",
    "```\n",
    "\n",
    "```console\n",
    "+--------------+-------------------+\n",
    "|         label|         prediction|\n",
    "+--------------+-------------------+\n",
    "| 163.877101489| 159.06994708337518|\n",
    "|-105.023368852| -99.52598722329135|\n",
    "|-115.011801582|-109.91382979074436|\n",
    "|-122.623452696|-118.62864861627764|\n",
    "|-117.130523174|-116.89245751669506|\n",
    "+--------------+-------------------+\n",
    "only showing top 5 rows\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "17142a6e7131d10366b0dc029fdf1b1e",
     "grade": true,
     "grade_id": "cell-966429bd3d48aa0a",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts:\n",
    "np.testing.assert_equal(set(predictions_df.columns), {'label', 'prediction'})\n",
    "np.testing.assert_equal(predictions_df.count(), 10000)\n",
    "np.testing.assert_equal(type(lr_model), regression.LinearRegressionModel)\n",
    "np.testing.assert_equal(type(va), feature.VectorAssembler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The root mean squared error is defined as\n",
    "\n",
    "$$ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i)^2}$$\n",
    "\n",
    "Combine functions in `fn` package and other functions to create a dataframe called `rmse_df` that contains the root mean squared error in column `rmse` based on the `predictions_df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "33a4b6cd52e592b1234d54a918a0550c",
     "grade": false,
     "grade_id": "cell-926f142075117a76",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|8.518758143015017|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diff = predictions_df.withColumn(\"diff\",predictions_df[\"prediction\"]-predictions_df[\"label\"])\n",
    "diff_pow = diff.withColumn(\"pow\",pow(diff[\"diff\"],2))\n",
    "rmse_df = diff_pow.agg((fn.sqrt(fn.sum('pow')/fn.count('diff'))).alias('rmse'))\n",
    "rmse_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cab72e6d6c675bca35428c189508d683",
     "grade": true,
     "grade_id": "cell-ce1df3212ea78b19",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_array_less(rmse_df.first().rmse, 10)\n",
    "np.testing.assert_equal(rmse_df.count(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Add the constant 10 to each feature in `requests_df` and redo the analytics pipeline from Q5, creating a vector assembler `va2`, `features2_df`, `lr_model2`, and `predictions2_df`. When adding the constant 10, preserve the column names in `features2_df` such that the columns in this new dataframe should be `f1` thorugh `f8`. Do not modify the column `label`. Fit a new linear model, similar to question 4, compute its root mean square error, and store it in `rmse2_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "af7de031344a62e47f17d42fd9512ba6",
     "grade": false,
     "grade_id": "cell-41b0350bc300afd9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+--------+------------------+--------+--------+--------+--------------+\n",
      "|  f1|      f2|      f3|      f4|                f5|      f6|      f7|      f8|         label|\n",
      "+----+--------+--------+--------+------------------+--------+--------+--------+--------------+\n",
      "|10.0|10.00008|10.45592|10.25362|           9.87122|  9.9307|  9.8526| 9.46264|-106.947151761|\n",
      "|10.0| 9.99999|10.10405| 9.82953|          10.10127|10.13776|10.66619|10.32221| 127.061566761|\n",
      "|11.0| 9.99999| 9.27606|10.31161|          10.06975| 10.0086| 9.55183| 9.77024|-170.222653879|\n",
      "|11.0|10.00024| 9.87113| 9.98713|10.183769999999999| 9.92996|10.10632| 9.59116|-127.850350049|\n",
      "|11.0|10.00006| 9.93233|10.08402|          10.14438| 9.80296| 10.2839| 9.87513|-110.295233798|\n",
      "+----+--------+--------+--------+------------------+--------+--------+--------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----+--------+--------+--------+--------+--------+--------+--------+--------------+--------------------+\n",
      "|  f1|      f2|      f3|      f4|      f5|      f6|      f7|      f8|         label|            features|\n",
      "+----+--------+--------+--------+--------+--------+--------+--------+--------------+--------------------+\n",
      "|10.0|10.00008|10.45592|10.25362| 9.87122|  9.9307|  9.8526| 9.46264|-106.947151761|[10.0,10.00008,10...|\n",
      "|10.0| 9.99999|10.10405| 9.82953|10.10127|10.13776|10.66619|10.32221| 127.061566761|[10.0,9.99999,10....|\n",
      "|11.0| 9.99999| 9.27606|10.31161|10.06975| 10.0086| 9.55183| 9.77024|-170.222653879|[11.0,9.99999,9.2...|\n",
      "+----+--------+--------+--------+--------+--------+--------+--------+--------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------+-------------------+\n",
      "|         label|         prediction|\n",
      "+--------------+-------------------+\n",
      "|-106.947151761| -98.40931839379482|\n",
      "| 127.061566761| 107.50926147797145|\n",
      "|-170.222653879|-165.34219556069002|\n",
      "|-127.850350049|-107.50564918713644|\n",
      "|-110.295233798|-109.90494159888476|\n",
      "+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|8.518758149923839|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "requests2_df = requests_df.select((fn.col('f1')+10).alias('f1'),\n",
    "                                 (fn.col('f2')+10).alias('f2'),\n",
    "                                 (fn.col('f3')+10).alias('f3'),\n",
    "                                 (fn.col('f4')+10).alias('f4'),\n",
    "                                 (fn.col('f5')+10).alias('f5'),\n",
    "                                 (fn.col('f6')+10).alias('f6'),\n",
    "                                 (fn.col('f7')+10).alias('f7'),\n",
    "                                 (fn.col('f8')+10).alias('f8'),\n",
    "                                 'label'\n",
    "                                )\n",
    "requests2_df.show(5)\n",
    "va2 = VectorAssembler(inputCols=['f1','f2','f3','f4','f5','f6','f7','f7','f8'],outputCol='features')\n",
    "features2_df = va2.transform(requests2_df)\n",
    "features2_df.show(3)\n",
    "lr2 = regression.LinearRegression(featuresCol='features',labelCol='label')\n",
    "lr_model2 = lr2.fit(features2_df)\n",
    "predictions2_df1 = lr_model2.transform(features2_df)\n",
    "predictions2_df= predictions2_df1.select(['label','prediction'])\n",
    "predictions2_df.show(5)\n",
    "diff2 = predictions2_df.withColumn(\"diff\",predictions2_df[\"prediction\"]-predictions2_df[\"label\"])\n",
    "diff2_pow = diff2.withColumn(\"pow\",pow(diff2[\"diff\"],2))\n",
    "rmse2_df = diff2_pow.agg((fn.sqrt(fn.sum('pow')/fn.count('diff'))).alias('rmse'))\n",
    "rmse2_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c26d79182d21ff9debc8f3c25934d7f8",
     "grade": true,
     "grade_id": "cell-978de063c691abb7",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts:\n",
    "np.testing.assert_equal(set(predictions2_df.columns), {'label', 'prediction'})\n",
    "np.testing.assert_equal(predictions2_df.count(), 10000)\n",
    "np.testing.assert_equal(type(va2), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(lr_model2), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_less(rmse2_df.first().rmse, 10)\n",
    "np.testing.assert_equal(rmse2_df.count(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the root mean squared error of Q5 and Q6. They should be almost exactly the same. Also, compare the coefficients and intercepts of `lr_model` and `lr_model2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Q5\n",
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|8.518758143015017|\n",
      "+-----------------+\n",
      "\n",
      "RMSE Q6\n",
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|8.518758149923839|\n",
      "+-----------------+\n",
      "\n",
      "intercept lr_model -29.021294776587045\n",
      "intercept lr_model2 -1693217.0787756755\n",
      "coefficients lr_model [18.11935595015397,168571.48581162572,142.7430866560904,0.017768599744867115,0.5163985972921608,360.13479650837576,-0.018413421964002318,228.77831544950865]\n",
      "coefficients lr_model2 [18.119351093982804,168568.51440463657,142.74310090574212,0.017766615555002436,0.5164495783656489,360.134797865094,-0.008251869226052411,-0.010179378486594937,228.77830861389268]\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE Q5\")\n",
    "rmse_df.show()\n",
    "print(\"RMSE Q6\")\n",
    "rmse2_df.show()\n",
    "print(\"intercept lr_model\", lr_model.intercept)\n",
    "print(\"intercept lr_model2\", lr_model2.intercept)\n",
    "print(\"coefficients lr_model\", lr_model.coefficients)\n",
    "print(\"coefficients lr_model2\", lr_model2.coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 pts for your answer below:** Comment on why there are differences or similarities between coefficients, intercepts, RMSE, even though we modified the features. You can use [Latex in Markdown](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html#LaTeX-equations) to put some math into your explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cd5984ba2cba0e00d13e96234557af17",
     "grade": true,
     "grade_id": "cell-29b2a054968a563c",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The RMSE values and coefficients are same but the intercept of both the models is different. As the coefficients are same for both models if some of the features are kept constant the answer for the features we are finding the values of will be same. The value of label will be the intercept for that linear model as the noise of 10 was added to each feature. The similarity is because the data points are the same with added noise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
